{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionImg2ImgPipeline, AutoencoderKL,StableDiffusionPipeline\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b62b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da83880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding.embedding import EmbeddingExtent\n",
    "from embedding.text_encoder_hijack import TextEncoderHijack\n",
    "from embedding.textual_inversion import TextualInversionPlug\n",
    "\n",
    "from cn_process import ControlNetProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DiffusionPipeline.from_pretrained(\"../model/diffuser_model/\",torch_dtype=torch.float16,safety_checker=None)\n",
    "\n",
    "# vae = AutoencoderKL.from_pretrained(\"vae_path\",torch_dtype=torch.float16,subfolder=\"vae\").to(\"cuda\")\n",
    "# generator.vae = vae\n",
    "\n",
    "generator.scheduler = EulerDiscreteScheduler.from_config(generator.scheduler.config)\n",
    "\n",
    "generator.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_Tokenizer = generator.tokenizer\n",
    "CLIP_TextModel = generator.text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TextualInversion\n",
    "TextualInversion = TextualInversionPlug('../model/textual_inversion',tokenizer = CLIP_Tokenizer)\n",
    "TextualInversion.load_textual_inversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hijack = TextEncoderHijack()\n",
    "hijack.hijack_embeding(CLIP_TextModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = EmbeddingExtent(tokenizer=CLIP_Tokenizer,text_encoder=CLIP_TextModel,textual_inversion_manager=TextualInversion,hijack=hijack,device=\"cuda\",dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7817d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Masterpiece, high quality, high detail, (((realistic))),(3d:1.2), solo, detailed beautiful face and eyes, Chinese clothes, detailed background, water, illustrations, vivid colors, movie-like lighting\"\n",
    "\n",
    "negative = \"Dark skin,((nsfw:1.3)),(EasyNegative:1.3),(badhandv4:1.5),(ng_deepnegative_v1_75t:1.2),(worst quality:1.5),(low quality:1.2),watermark,username,text,(cameltoe:1.3),((realistic:1.3)),((long pointy ears:1.3)),((forehead:1.3)),((watermark:1.3)),(((animal ears:1.3))),jacket\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP_stop_at_last_layers is clip_skip in webui\n",
    "prompt_pre_embedding = embedding(prompt,CLIP_stop_at_last_layers=1)\n",
    "negative_prompt_pre_embedding = embedding(negative,CLIP_stop_at_last_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_pre_embedding,negative_prompt_pre_embedding = embedding.pad_prompt_tensor_same_length(prompt_emb=prompt_pre_embedding, negative_prompt_emb=negative_prompt_pre_embedding,CLIP_stop_at_last_layers=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_names=['canny']\n",
    "preprocess_model_path='../model/controlNet/preprocess_model'\n",
    "preprocess_params=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "controlnet_names=['canny']\n",
    "controlnet_model_path='../model/controlNet'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cn = ControlNetProcess(generator=generator, controlnet_names=controlnet_names,preprocess_names=preprocess_names,controlnet_model_path=controlnet_model_path,preprocess_model_path=preprocess_model_path,device='cuda')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "apply_lora_list = []\n",
    "cn_img = Image.open('../canny.png')\n",
    "tile_img = Image.open('../tile.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cn_info = {\n",
    "    \"cn_image\":cn_img,\n",
    "    \"cn_model_name\":\"depth\",\n",
    "    \"cn_model_scale\":0.5,\n",
    "    \"cn_pre_model_name\":\"depth_leres++\"\n",
    "}\n",
    "\n",
    "# cn_info = [{\n",
    "#     \"cn_image\":cn_img,\n",
    "#     \"cn_model_name\":\"depth\",\n",
    "#     \"cn_model_scale\":0.5,\n",
    "#     \"cn_pre_model_name\":\"depth_leres++\"\n",
    "# },{\n",
    "#     \"cn_image\":cn_img,\n",
    "#     \"cn_model_name\":\"canny\",\n",
    "#     \"cn_model_scale\":0.8,\n",
    "#     \"cn_pre_model_name\":\"canny\"\n",
    "# }]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image,info = cn(prompt_embeds=prompt_pre_embedding,\n",
    "                width=512,\n",
    "                height=768,\n",
    "                negative_prompt_embeds=negative_prompt_pre_embedding,\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative,\n",
    "                apply_lora_list=apply_lora_list,\n",
    "                controlnet_info=cn_info,\n",
    "                guidance_scale=7,\n",
    "                num_inference_steps=20,\n",
    "                num_images_per_prompt=1,\n",
    "               guess_mode=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630703d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wy_py310",
   "language": "python",
   "name": "wy_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
