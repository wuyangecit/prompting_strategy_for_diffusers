{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionImg2ImgPipeline, AutoencoderKL,StableDiffusionPipeline\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b62b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da83880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora_utils import LoRAModuleWeight, LoRAHook, LoRAHookInjector\n",
    "from embedding.embedding import EmbeddingExtent\n",
    "from embedding.text_encoder_hijack import TextEncoderHijack\n",
    "from embedding.textual_inversion import TextualInversionPlug\n",
    "\n",
    "from convert_prompt_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DiffusionPipeline.from_pretrained(\"../model/diffuser_model/\",torch_dtype=torch.float16,safety_checker=None)\n",
    "\n",
    "# vae = AutoencoderKL.from_pretrained(\"vae_path\",torch_dtype=torch.float16,subfolder=\"vae\").to(\"cuda\")\n",
    "# generator.vae = vae\n",
    "\n",
    "generator.scheduler = EulerDiscreteScheduler.from_config(generator.scheduler.config)\n",
    "\n",
    "generator.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795f960",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#local lora model path\n",
    "lora_dir_path = './model/lora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "module_dict = {}\n",
    "def get_module_dict(module):\n",
    "    global module_dict\n",
    "    for lora_layer_name, hook in module.hooks.items():\n",
    "        module_class_name = hook.orig_module.__class__.__name__\n",
    "        module_dict[lora_layer_name] = module_class_name\n",
    "\n",
    "get_module_dict(generator.lora_injector)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preload_loras(loaded_loras, lora_dir_path):\n",
    "    \"\"\"\n",
    "    preload lora list from file_path at project starting\n",
    "    \"\"\"\n",
    "    for file_name in os.listdir(lora_dir_path):\n",
    "        if file_name.split(\".\")[-1] == \"safetensors\":\n",
    "            lora = file_name.split(\".\")[0]\n",
    "            if lora not in loaded_loras:\n",
    "                lora_name, LoraWeight = load_lora_from_disk(lora_dir_path, file_name)\n",
    "                if lora_name == \"\":\n",
    "                    continue\n",
    "                loaded_loras[lora_name] = LoraWeight\n",
    "\n",
    "def load_lora_by_name(loaded_loras: dict, lora_dir_path: str,lora_name: str):\n",
    "    \"\"\"\n",
    "    if lora file add in dir after project starting, load it from disk by lora name\n",
    "    \"\"\"\n",
    "    if lora_name in loaded_loras:\n",
    "        return True\n",
    "    file_name = lora_name + \".safetensors\"\n",
    "    lora_name_loaded, LoraWeight = load_lora_from_disk(lora_dir_path, file_name)\n",
    "    if lora_name_loaded == \"\":\n",
    "        return False\n",
    "    loaded_loras[lora_name_loaded] = LoraWeight\n",
    "    return True\n",
    "\n",
    "def load_lora_from_disk(lora_dir_path: str, file_name: str):\n",
    "    if not os.path.exists(os.path.join(lora_dir_path, file_name)):\n",
    "        return \"\", None\n",
    "    if file_name.split(\".\")[-1] == \"safetensors\":\n",
    "        lora_name = file_name.split(\".\")[0]\n",
    "        state_dict = safetensors.torch.load_file(os.path.join(lora_dir_path, file_name))\n",
    "        LoraWeight = LoRAModuleWeight(lora_name, module_dict, state_dict, 1.0, \"cuda\", torch.float16)\n",
    "        return lora_name, LoraWeight\n",
    "\n",
    "loaded_loras = {}\n",
    "preload_loras(loaded_loras, lora_dir_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "def torch_gc():\n",
    "    if torch.cuda.is_available():\n",
    "        with torch.cuda.device('cuda'):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "\n",
    "def get_lora_by_nameList(lora_name_list):\n",
    "    global loaded_loras\n",
    "    res_lora_list = []\n",
    "    for lora_name,weight in lora_name_list:\n",
    "        if lora_name in loaded_loras:\n",
    "            res_lora_list.append((loaded_loras[lora_name],weight))\n",
    "        else:\n",
    "            if load_lora_by_name(loaded_loras, lora_dir_path, lora_name):\n",
    "                res_lora_list.append((loaded_loras[lora_name],weight))\n",
    "            else:\n",
    "                print(f'load lora {lora_name} failed, lora name not exist')\n",
    "    return res_lora_list\n",
    "\n",
    "def add_lora_weight_to_pipeline(pipeline, lora_name_list):\n",
    "    apply_lora_list = []\n",
    "    lora_list = get_lora_by_nameList(lora_name_list)\n",
    "    for lora_weight, multiple in lora_list:\n",
    "        if isinstance(multiple, str):\n",
    "            multiple = float(multiple)\n",
    "        pipeline.load_lora(lora_weight,multiple)\n",
    "        apply_lora_list.append((lora_weight.lora_name,multiple))\n",
    "    pipeline.apply_lora()\n",
    "    return apply_lora_list\n",
    "\n",
    "def clear_lora_weight_from_pipeline(pipeline):\n",
    "    pipeline.clear_lora()\n",
    "    gc.collect()\n",
    "    torch_gc()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def install_lora_hook(pipe: DiffusionPipeline):\n",
    "    \"\"\"Install LoRAHook to the pipe.\"\"\"\n",
    "    if hasattr(pipe, \"lora_injector\"):\n",
    "        return\n",
    "    else:\n",
    "        injector = LoRAHookInjector()\n",
    "        injector.install_hooks(pipe)\n",
    "        pipe.lora_injector = injector\n",
    "        pipe.load_lora = injector.load_lora\n",
    "        pipe.apply_lora = injector.apply_lora\n",
    "        pipe.clear_lora = injector.clear_lora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "install_lora_hook(generator)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLIP_Tokenizer = generator.tokenizer\n",
    "CLIP_TextModel = generator.text_encoder\n",
    "\n",
    "# load TextualInversion\n",
    "TextualInversion = TextualInversionPlug('textual_inversion_path',tokenizer = CLIP_Tokenizer)\n",
    "TextualInversion.load_textual_inversion()\n",
    "\n",
    "hijack = TextEncoderHijack()\n",
    "hijack.hijack_embeding(CLIP_TextModel)\n",
    "\n",
    "embedding = EmbeddingExtent(tokenizer=CLIP_Tokenizer,text_encoder=CLIP_TextModel,textual_inversion_manager=TextualInversion,hijack=hijack,device=\"cuda\",dtype=torch.float16)\n",
    "\n",
    "prompt = \"(absurdres, highres, ultra detailed), 1 male, handsome, tall muscular guy, very short hair, best ratio four finger and one thumb, best light and shadow, background is back alley, detasiled sunlight, sitting, Little cats are gathered next to him, dappled sunlight, day, depth of field, plants, summer, (dutch angle), closed mouth, summer day\"\n",
    "\n",
    "\n",
    "negative = \"(hair between eyes), sketch, duplicate, ugly, huge eyes, text, logo, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), ((2girl)), (deformed fingers:1.2), (long fingers:1.2), extra legs, upper teeth, parted lips, open mouth\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt, lora_name_list = find_and_replace_lora(prompt)\n",
    "if lora_name_list != None and len(lora_name_list) > 0:\n",
    "    apply_lora_list = add_lora_weight_to_pipeline(generator, lora_name_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt_pre_embedding = embedding(prompt,CLIP_stop_at_last_layers=1)\n",
    "negative_prompt_pre_embedding = embedding(negative,CLIP_stop_at_last_layers=1)\n",
    "\n",
    "prompt_pre_embedding,negative_prompt_pre_embedding = embedding.pad_prompt_tensor_same_length(prompt_emb=prompt_pre_embedding, negative_prompt_emb=negative_prompt_pre_embedding,CLIP_stop_at_last_layers=1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = int(random.randrange(4294967294))\n",
    "# seed=4196966724\n",
    "print(seed)\n",
    "Generator = [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(seed, seed + 1)]\n",
    "\n",
    "\n",
    "image = generator(prompt_embeds=prompt_pre_embedding,\n",
    "                  width=512,\n",
    "                  height=768,\n",
    "                  negative_prompt_embeds=negative_prompt_pre_embedding,\n",
    "                  num_inference_steps=20,\n",
    "                  guidance_scale=9,\n",
    "                  generator=Generator,\n",
    "                  num_images_per_prompt=1).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630703d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_lora_weight_from_pipeline(generator)\n",
    "torch_gc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wy_py310",
   "language": "python",
   "name": "wy_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
